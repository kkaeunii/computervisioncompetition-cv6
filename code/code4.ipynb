{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2165d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리를 설치합니다.\n",
    "# PyTorch 기반 SOTA 이미지 모델 라이브러리 ; resnet34 불러오기 위함\n",
    "!pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef0fbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import timm # 모델\n",
    "import torch\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import Adam\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from PIL import Image # 이미지 입출력\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0decfbda",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6b7056",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "CANDIDATES = [Path(\".\"), Path(\"..\"), Path(\"../..\"), Path(\"../../..\")]\n",
    "ROOT = None\n",
    "for base in CANDIDATES:\n",
    "    if (base / \"train.csv\").exists() and (base / \"train\").exists():\n",
    "        ROOT = base.resolve()\n",
    "        break\n",
    "if ROOT is None:\n",
    "    raise FileNotFoundError(\"train.csv 및 train 폴더를 찾지 못했습니다.\")\n",
    "\n",
    "TRAIN_DIR = ROOT / \"train\"\n",
    "print(\"ROOT:\", ROOT)\n",
    "print(\"TRAIN_DIR exists:\", TRAIN_DIR.exists())\n",
    "\n",
    "train_df = pd.read_csv(ROOT / \"train.csv\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71ff505",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "counts = train_df[\"target\"].value_counts().sort_index()\n",
    "display(counts)\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "sns.barplot(x=counts.index, y=counts.values)\n",
    "plt.title(\"Label distribution\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n",
    "imbalance_ratio = counts.max() / counts.min()\n",
    "print(f\"Imbalance ratio (max/min): {imbalance_ratio:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7caa35f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_id = train_df.duplicated(subset=[\"ID\"]).sum()\n",
    "dup_pair = train_df.duplicated(subset=[\"ID\",\"target\"]).sum()\n",
    "id_conflict = (train_df.groupby(\"ID\")[\"target\"].nunique()>1).sum()\n",
    "\n",
    "print(\"중복 ID:\", dup_id)\n",
    "print(\"중복 (ID,target):\", dup_pair)\n",
    "print(\"서로 다른 라벨을 가진 ID(라벨 충돌):\", id_conflict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c741b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, UnidentifiedImageError\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "missing, unreadable, flat_images, modes = [], [], [], []\n",
    "\n",
    "for fname in tqdm(train_df[\"ID\"]):\n",
    "    p = TRAIN_DIR / fname\n",
    "    if not p.exists():\n",
    "        missing.append(fname)\n",
    "        continue\n",
    "    try:\n",
    "        im = Image.open(p)\n",
    "        modes.append(im.mode)\n",
    "        arr = np.array(im)\n",
    "        if arr.size == 0 or arr.std() == 0:\n",
    "            flat_images.append(fname)\n",
    "    except (UnidentifiedImageError, OSError):\n",
    "        unreadable.append(fname)\n",
    "\n",
    "print(\"없는 파일 수:\", len(missing))\n",
    "print(\"읽기 불가 파일 수:\", len(unreadable))\n",
    "print(\"단색/이상치 의심 수:\", len(flat_images))\n",
    "print(\"Image modes:\", Counter(modes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb398e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "widths, heights = [], []\n",
    "checked = 0\n",
    "for fname in train_df[\"ID\"]:\n",
    "    p = TRAIN_DIR / fname\n",
    "    if not p.exists():\n",
    "        continue\n",
    "    try:\n",
    "        im = Image.open(p)\n",
    "        w, h = im.size\n",
    "        widths.append(w); heights.append(h)\n",
    "        checked += 1\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(\"Checked images:\", checked)\n",
    "plt.figure(); plt.hist(widths, bins=30); plt.title(\"Width\"); plt.show()\n",
    "plt.figure(); plt.hist(heights, bins=30); plt.title(\"Height\"); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf9be50",
   "metadata": {},
   "source": [
    "# Transform(Albumentations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadced5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "IMG_SIZE = 224\n",
    "\n",
    "# 기본 학습 증강 : 기하/색상 약하게 + 표준화\n",
    "base_train_transform = A.Compose([\n",
    "    A.SmallestMaxSize(max_size=256),\n",
    "    A.CenterCrop(height=IMG_SIZE, width=IMG_SIZE),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.ShiftScaleRotate(shift_limit=0.03, scale_limit=0.10, rotate_limit=10, p=0.4),\n",
    "    A.ColorJitter(brightness=0.15, contrast=0.15, saturation=0.15, hue=0.03, p=0.4),\n",
    "    A.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "# 강한 학습 증강 : 소수 클래스에만 적용 (의도적 노이즈 포함)\n",
    "strong_train_transform=A.Compose([\n",
    "    A.SmallestMaxSize(max_size=256),\n",
    "    A.CenterCrop(height=IMG_SIZE, width=IMG_SIZE),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.ShiftScaleRotate(shift_limit=0.06, scale_limit=0.15, rotate_limit=15, p=0.7),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.25, contrast_limit=0.25, p=0.5),\n",
    "    A.CLAHE(clip_limit=2.0, p=0.2),\n",
    "    A.GaussNoise(var_limit=(5.0, 30.0), p=0.4),\n",
    "    A.MotionBlur(blur_limit=5, p=0.2),\n",
    "    A.JpegCompression(quality_lower=60, quality_upper=95, p=0.3),\n",
    "    A.CoarseDropout(max_holes=4, max_height=IMG_SIZE//8, max_width=IMG_SIZE//8, p=0.3),\n",
    "    A.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.255)),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "# 검증/테스트 : 학습과 동일한 전처리\n",
    "valid_transform = A.Compose([\n",
    "    A.SmallestMaxSize(max_size=256),\n",
    "    A.CenterCrop(height=IMG_SIZE, width=IMG_SIZE),\n",
    "    A.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "tst_transform = valid_transform\n",
    "\n",
    "trn_transform = base_train_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f17df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 클래스를 정의합니다.\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, csv, path, transform=None, transform_strong=None, minority_set=None):\n",
    "        self.df = pd.read_csv(csv).values\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "        self.transform_strong = transform_strong\n",
    "        self.minority_set = set(minority_set) if minority_set is not None else None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx): # DataLoader가 배치 단위로 호출할 때 행\n",
    "        name, target = self.df[idx]\n",
    "        target = int(target)\n",
    "        \n",
    "        # EXIF 회전 보정 + numpy 변환\n",
    "        img = np.array(Image.open(os.path.join(self.path, name))) # PIL.Image.open()으로 읽고 numpy array로 변환 img는 (H,W,C)형태 배열\n",
    "        img = ImageOps.exif_transpose(img)\n",
    "        img = np.array(img)\n",
    "        \n",
    "        # 클래스별로 강/약 증강 분기\n",
    "        t = self.transform\n",
    "        if (self.transform_strong is not None) and (self.minority_set is not None) and (target in self.minority_set):\n",
    "            t = self.transform_strong\n",
    "        \n",
    "        if t is not None:\n",
    "            img = t(image=img)['image']\n",
    "            \n",
    "        return img, target # (이미지 텐서, 라벨) 반환 -> DataLoader에서 (batch_size, C, H, W)형태로 묶임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213b19d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one epoch 학습을 위한 함수입니다.\n",
    "def train_one_epoch(loader, model, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    train_loss = 0 # 에폭 전체 손실 합계 저장\n",
    "    preds_list = [] # 모델 예측값 저장\n",
    "    targets_list = [] # 정답(라벨) 저장\n",
    "\n",
    "    pbar = tqdm(loader) # 진행 상태 출력\n",
    "    for image, targets in pbar: # DataLoader에서 image, targets(라벨)을 배치 단위로 불러옴\n",
    "        image = image.to(device) # 이미지를 GPU로 이동\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        model.zero_grad(set_to_none=True) # 이전 배치에서 계산된 gradient 초기화, 메모리 최적화\n",
    "\n",
    "        preds = model(image) # 모델 forward pass 수행으로 예측값 출력\n",
    "        loss = loss_fn(preds, targets) # 예측값과 정답을 비교해 손실 계산\n",
    "        loss.backward() # 역전파 파라미터별 gradient 계산\n",
    "        optimizer.step() # gradient를 이용해 모델 파라미터 업데이트\n",
    "\n",
    "        train_loss += loss.item() # 현재 배치 손실 누적\n",
    "        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "        targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "        pbar.set_description(f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "    train_loss /= len(loader)\n",
    "    train_acc = accuracy_score(targets_list, preds_list)\n",
    "    train_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "\n",
    "    ret = {\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_acc\": train_acc,\n",
    "        \"train_f1\": train_f1,\n",
    "    }\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade236e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def valid_one_epoch(loader, model, loss_fn, device):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    preds_all, t_all = [], []\n",
    "\n",
    "    for images, targets in loader:\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        logits = model(images)\n",
    "        loss = loss_fn(logits, targets)\n",
    "        val_loss += loss.item()\n",
    "\n",
    "        preds = logits.argmax(1)\n",
    "        preds_all.extend(preds.detach().cpu().numpy())\n",
    "        t_all.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "    val_loss /= len(loader)\n",
    "    val_acc = accuracy_score(t_all, preds_all)\n",
    "    val_f1  = f1_score(t_all, preds_all, average=\"macro\")\n",
    "    return {\"val_loss\": val_loss, \"val_acc\": val_acc, \"val_f1\": val_f1}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787a46f4",
   "metadata": {},
   "source": [
    "# 하이퍼파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe1f861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # cuda 하면 GPU 사용\n",
    "\n",
    "# data config\n",
    "data_path = '/root/cv_data/' # 데이터셋 저장 경로 : 이미지 폴더와 csv 파일들 위치\n",
    "\n",
    "# model config\n",
    "model_name = 'resnet34' # 'resnet50' 'efficientnet-b0', ...\n",
    "\n",
    "# training config\n",
    "img_size = 224 # 입력 이미지 크기인데 32는 너무 작으니 224 정도로 바꾸기 \n",
    "LR = 1e-3 # 학습률 AdamW은 1e-3 또는 5-4 / SGD는 1e-2 또는 1e-3 많이 사용\n",
    "EPOCHS = 20 # 20~50 정도 돌려보기\n",
    "BATCH_SIZE = 64 # 한번에 학습할 이미지 개수 -> GPU 메모리 용량에 따라 조정 64나 128이면 더 안정적인 gradient 추정\n",
    "num_workers = 0 # DataLoader의 병렬 데이터 로딩 worker 수 0이면 메인 프로세스에서만 로딩(느려짐) 서버는 4~8 권장(코어 수 따라)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b045c456",
   "metadata": {},
   "source": [
    "# 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f9189e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmentation을 위한 transform 코드\n",
    "trn_transform = A.Compose([\n",
    "    # 이미지 크기 조정\n",
    "    A.Resize(height=img_size, width=img_size),\n",
    "    # images normalization\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    # numpy 이미지나 PIL 이미지를 PyTorch 텐서로 변환\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "# test image 변환을 위한 transform 코드\n",
    "tst_transform = A.Compose([\n",
    "    A.Resize(height=img_size, width=img_size),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82469f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv(\"/root/cv_data/train.csv\")\n",
    "\n",
    "# 클래스 비율 유지하며 train/val 분리\n",
    "trn_df, val_df = train_test_split(\n",
    "    df,\n",
    "    test_size = 0.2, # 8:2 분리\n",
    "    stratify = df['target'], # 클래스 비율 유지\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 임시 csv 저장\n",
    "trn_df.to_csv('/root/cv_data/train_split.csv', index=False)\n",
    "val_df.to_csv('/root/cv_data/val_split.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72398741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset 정의\n",
    "# minority_set 로드\n",
    "minority_path = '/root/cv_data/minority_set.txt'\n",
    "if os.path.exists(minority_path):\n",
    "    with open(minority_path, 'r') as f:\n",
    "        txt = f.read().strip()\n",
    "    minority_set = set(map(int, txt.split(','))) if txt else set()\n",
    "else:\n",
    "    minority_set = set()\n",
    "    \n",
    "trn_dataset = ImageDataset(\n",
    "    \"/root/cv_data/train_split.csv\",\n",
    "    \"/root/cv_data/train\",\n",
    "    transform=trn_transform, # 약 증강\n",
    "    transform_strong=strong_train_transform, # 강 증강\n",
    "    minority_set=minority_set\n",
    ")\n",
    "\n",
    "val_dataset = ImageDataset(\n",
    "    \"/root/cv_data/val_split.csv\",\n",
    "    \"/root/cv_data/train\",\n",
    "    transform=tst_transform # val데이터와 tst데이터는 같은 방식으로 변환해야 하기 때문\n",
    ")\n",
    "\n",
    "tst_dataset = ImageDataset(\n",
    "    \"/root/cv_data/sample_submission.csv\",\n",
    "    \"/root/cv_data/test\",\n",
    "    transform=tst_transform\n",
    ")\n",
    "print(len(trn_dataset), len(val_dataset), len(tst_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca983f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader 정의\n",
    "# WeightedRandomSampler 적용\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "\n",
    "# sampler : 클래스 불균형 보정\n",
    "sample_weights = np.load('/root/cv_data/sample_weights.npy')\n",
    "sampler = WeightedRandomSampler(\n",
    "    weights=torch.tensor(sample_weights, dtype=torch.double),\n",
    "    num_samples=len(sample_weights),\n",
    "    replacement=True\n",
    ")\n",
    "\n",
    "trn_loader = DataLoader(\n",
    "    trn_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    sampler=sampler, # shuffle이 false여서 shuffle 대신 sampler 사용\n",
    "    shuffle=False, # 매 에폭마다 데이터 섞어서 배치 구성\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True, # gpu 전송을 빠르게 하기 위해 메모리 고정\n",
    "    drop_last=False # 데이터 수가 배치 크기로 안 나눠떨어질 때 마지막 배치 버릴지 여부\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "tst_loader = DataLoader(\n",
    "    tst_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False, # 테스트 용은 데이터 순서 유지해야 함\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fad5b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model = timm.create_model(\n",
    "    model_name,        # ex) \"resnet34\", \"efficientnet-b0\"\n",
    "    pretrained=True,   # ImageNet 사전학습 가중치 사용\n",
    "    num_classes=17     # 대회 클래스 개수\n",
    ").to(device)\n",
    "\n",
    "# 클래스 가중치(CE Loss)\n",
    "class_weights = torch.tensor(np.load('/root/cv_data/class_weights.npy'), dtype=torch.float, device=device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss(\n",
    "    weight=class_weights,\n",
    "    label_smoothing=0.05 # 라벨 노이즈/경계 완화\n",
    ")\n",
    "\n",
    "# Optimizer (Adam → AdamW)\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=LR,             # 초기 learning rate (예: 1e-3)\n",
    "    weight_decay=1e-4  # 정규화 효과, 과적합 방지\n",
    ")\n",
    "\n",
    "# Scheduler (CosineAnnealingLR)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=EPOCHS,      # 전체 epoch 수와 맞춤\n",
    "    eta_min=1e-6       # 최소 learning rate (0까지 떨어지지 않도록)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547863bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31139fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_f1 = -1.0  # 가장 높은 val macro-F1 저장용, -1.0으로 초기화(첫 에포크 성능은 무조건 갱신되도록)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # 1) Train\n",
    "    tr = train_one_epoch(trn_loader, model, optimizer, loss_fn, device)\n",
    "\n",
    "    # 2) Validation 한 에포크 끝나고 검증\n",
    "    va = valid_one_epoch(val_loader, model, loss_fn, device)\n",
    "\n",
    "    # 3) Scheduler step (CosineAnnealingLR이면 epoch마다 호출 - 그래야 학습률 변함)\n",
    "    scheduler.step()\n",
    "\n",
    "    # 4) 로그 출력\n",
    "    curr_lr = optimizer.param_groups[0][\"lr\"] # 현재 optimizer가 쓰는 학습률 가져옴\n",
    "    print(\n",
    "        f\"[{epoch+1:02d}/{EPOCHS}] \" # 두 자리 정수로 출력\n",
    "        f\"train_loss={tr['train_loss']:.4f}  train_f1={tr['train_f1']:.4f}  \"\n",
    "        f\"val_loss={va['val_loss']:.4f}  val_f1={va['val_f1']:.4f}  lr={curr_lr:.6f}\"\n",
    "    )\n",
    "\n",
    "    # 5) 베스트 모델 체크포인트 (대회 지표: macro-F1)\n",
    "    if va[\"val_f1\"] > best_f1: \n",
    "        best_f1 = va[\"val_f1\"]\n",
    "        torch.save(model.state_dict(), \"best_resnet34_2.pth\")\n",
    "        print(f\">> best updated! val_f1={best_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b210199",
   "metadata": {},
   "source": [
    "# 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63359e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) best 모델 가중치 불러오기\n",
    "model.load_state_dict(torch.load(\"best_resnet34_2.pth\", map_location=device))\n",
    "model.to(device)\n",
    "model.eval()  # 평가 모드 전환\n",
    "\n",
    "# 2) 추론 실행\n",
    "preds_list = []\n",
    "with torch.no_grad():  # 추론 시 gradient 계산 안 함, 한번에 감싸고 루프 전 모델 로드(가장 좋은 가중치로 추론하기 위함)\n",
    "    for image, _ in tqdm(tst_loader):\n",
    "        image = image.to(device)\n",
    "\n",
    "        preds = model(image)  # (batch_size, num_classes) 출력\n",
    "        preds = preds.argmax(dim=1)  # 가장 확률 높은 클래스 선택\n",
    "\n",
    "        preds_list.extend(preds.detach().cpu().numpy())  # numpy로 변환 후 리스트에 추가\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1f5c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(tst_dataset.df, columns=['ID', 'target'])\n",
    "pred_df['target'] = preds_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8bddba",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb746e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission_df = pd.read_csv(\"/root/cv_data/sample_submission.csv\")\n",
    "assert (sample_submission_df['ID'] == pred_df['ID']).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4545b511",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.to_csv(\"code2_pred.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2467d8db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
