{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4bf7f16",
   "metadata": {},
   "source": [
    "# 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb4eb41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import Adam\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from sklearn.model_selection import train_test_split\n",
    "import albumentations as A\n",
    "from torch.cuda.amp import autocast, GradScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7dd5302e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7407c28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시드를 고정합니다.\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b1ac178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 클래스를 정의합니다.\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, csv, path, transform=None):\n",
    "        self.df = pd.read_csv(csv).values\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx]\n",
    "        img = np.array(Image.open(os.path.join(self.path, name)))\n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)['image']\n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2f31250f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 클래스를 정의합니다.\n",
    "class ImageDataset2(Dataset):\n",
    "    def __init__(self, df, path, transform=None):\n",
    "        #self.df = pd.read_csv(csv).values\n",
    "        self.df = df.values\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx]\n",
    "        img = np.array(Image.open(os.path.join(self.path, name)))\n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)['image']\n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b4f1eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one epoch 학습을 위한 함수입니다.\n",
    "def train_one_epoch(loader, model, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    pbar = tqdm(loader)\n",
    "    for image, targets in pbar:\n",
    "        image = image.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #model.zero_grad(set_to_none=True)\n",
    "\n",
    "        with autocast():\n",
    "            preds = model(image)\n",
    "            loss = loss_fn(preds, targets)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "        targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "        pbar.set_description(f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "    train_loss /= len(loader)\n",
    "    train_acc = accuracy_score(targets_list, preds_list)\n",
    "    train_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "\n",
    "    ret = {\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_acc\": train_acc,\n",
    "        \"train_f1\": train_f1,\n",
    "    }\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec38f428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid epoch\n",
    "def validate_one_epoch(loader, model, loss_fn, device):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for image, targets in tqdm(loader):\n",
    "            image = image.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            with autocast():\n",
    "                preds = model(image)\n",
    "                loss = loss_fn(preds, targets)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            preds_list.extend(preds.argmax(dim=1).cpu().numpy())\n",
    "            targets_list.extend(targets.cpu().numpy())\n",
    "\n",
    "    val_loss /= len(loader)\n",
    "    val_acc = accuracy_score(targets_list, preds_list)\n",
    "    val_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "\n",
    "    return {\n",
    "        \"val_loss\": val_loss,\n",
    "        \"val_acc\": val_acc,\n",
    "        \"val_f1\": val_f1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4967a317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# data config\n",
    "#data_path = 'datasets_fin/'\n",
    "data_path = '../'\n",
    "\n",
    "# model config\n",
    "model_name = 'resnet50'\n",
    "\n",
    "# training config\n",
    "img_size = 224\n",
    "LR = 1e-3\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 64\n",
    "num_workers = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d792d5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/albumentations/augmentations/dropout/cutout.py:49: FutureWarning: Cutout has been deprecated. Please use CoarseDropout\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trn_transform = A.Compose([\n",
    "    A.Resize(img_size, img_size),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.2),\n",
    "    A.RandomBrightnessContrast(p=0.5),\n",
    "    A.ColorJitter(p=0.4),\n",
    "    A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.1, rotate_limit=15, p=0.7),\n",
    "\n",
    "    A.MotionBlur(p=0.2),\n",
    "    A.OpticalDistortion(p=0.2),\n",
    "    A.Cutout(max_h_size=int(img_size*0.1), max_w_size=int(img_size*0.1), num_holes=5, p=0.5),\n",
    "\n",
    "    A.GridDistortion(p=0.3),\n",
    "    A.CoarseDropout(max_holes=8, max_height=img_size//10, max_width=img_size//10, p=0.5),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "31e1a586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test image 변환을 위한 transform 코드\n",
    "tst_transform = A.Compose([\n",
    "    A.Resize(height=img_size, width=img_size),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5995a5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1413 3140\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../train.csv\")\n",
    "\n",
    "# stratify를 통해 클래스 비율 유지\n",
    "train_df, val_df = train_test_split(\n",
    "    df,\n",
    "    #test_size=0.2,\n",
    "    test_size=0.1,\n",
    "    stratify=df['target'],\n",
    "    random_state=SEED\n",
    ")\n",
    "\n",
    "trn_dataset = ImageDataset2(train_df, \"../train/\", transform=trn_transform)\n",
    "val_dataset = ImageDataset2(val_df, \"../train/\", transform=tst_transform)\n",
    "\n",
    "\n",
    "tst_dataset = ImageDataset(\n",
    "    \"../sample_submission.csv\",\n",
    "    \"../test/\",\n",
    "    transform=tst_transform\n",
    ")\n",
    "print(len(trn_dataset), len(tst_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "067d7f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader 정의\n",
    "trn_loader = DataLoader(\n",
    "    trn_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "tst_loader = DataLoader(\n",
    "    tst_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2ac4d508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cb5a47051994ddf8471e9052eb52cc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/102M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load model\n",
    "model = timm.create_model(\n",
    "    model_name,\n",
    "    pretrained=True,\n",
    "    num_classes=17\n",
    ").to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "#optimizer = Adam(model.parameters(), lr=LR)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=10, eta_min=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1599c982",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.5914: 100%|██████████| 23/23 [00:08<00:00,  2.85it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  4.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - val_f1: 0.3375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.6746: 100%|██████████| 23/23 [00:08<00:00,  2.85it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  4.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - val_f1: 0.3772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.5074: 100%|██████████| 23/23 [00:08<00:00,  2.86it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  4.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - val_f1: 0.5065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.3600: 100%|██████████| 23/23 [00:08<00:00,  2.87it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  4.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - val_f1: 0.5186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.3250: 100%|██████████| 23/23 [00:08<00:00,  2.82it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  4.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 - val_f1: 0.5494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.1502: 100%|██████████| 23/23 [00:08<00:00,  2.85it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  4.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 - val_f1: 0.5667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.5319: 100%|██████████| 23/23 [00:08<00:00,  2.84it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  4.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 - val_f1: 0.5892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.7170: 100%|██████████| 23/23 [00:08<00:00,  2.85it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  4.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 - val_f1: 0.6107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.8308: 100%|██████████| 23/23 [00:08<00:00,  2.81it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  4.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 - val_f1: 0.6292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.3145: 100%|██████████| 23/23 [00:08<00:00,  2.86it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  4.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 - val_f1: 0.6617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1418: 100%|██████████| 23/23 [00:08<00:00,  2.86it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  4.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 - val_f1: 0.7123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3327: 100%|██████████| 23/23 [00:08<00:00,  2.82it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  4.70it/s]\n",
      "Loss: 0.9349: 100%|██████████| 23/23 [00:08<00:00,  2.83it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 - val_f1: 0.7233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5892: 100%|██████████| 23/23 [00:08<00:00,  2.86it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  4.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 - val_f1: 0.7824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2500: 100%|██████████| 23/23 [00:08<00:00,  2.84it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  4.73it/s]\n",
      "Loss: 0.7976: 100%|██████████| 23/23 [00:08<00:00,  2.86it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  4.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 - val_f1: 0.7884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.9246: 100%|██████████| 23/23 [00:08<00:00,  2.85it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 - val_f1: 0.7922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4200: 100%|██████████| 23/23 [00:08<00:00,  2.86it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  4.63it/s]\n",
      "Loss: 1.2612: 100%|██████████| 23/23 [00:08<00:00,  2.86it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  4.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 - val_f1: 0.7936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3779: 100%|██████████| 23/23 [00:08<00:00,  2.85it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  4.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 - val_f1: 0.8029\n"
     ]
    }
   ],
   "source": [
    "best_f1 = 0\n",
    "for epoch in range(EPOCHS):\n",
    "    train_ret = train_one_epoch(trn_loader, model, optimizer, loss_fn, device=device)\n",
    "    val_ret = validate_one_epoch(val_loader, model, loss_fn, device=device)  # 따로 구현 필요\n",
    "\n",
    "    if val_ret['val_f1'] > best_f1:\n",
    "        print(f\"Epoch {epoch} - val_f1: {val_ret['val_f1']:.4f}\")\n",
    "\n",
    "        best_f1 = val_ret['val_f1']\n",
    "        torch.save(model.state_dict(), 'best_model2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8bc1ab5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:14<00:00,  3.44it/s]\n"
     ]
    }
   ],
   "source": [
    "# 저장된 가중치 로드\n",
    "model.load_state_dict(torch.load('best_model2.pth'))\n",
    "\n",
    "preds_list = []\n",
    "\n",
    "model.eval()\n",
    "for image, _ in tqdm(tst_loader):\n",
    "    image = image.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        preds = model(image)\n",
    "    preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6e72fb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(tst_dataset.df, columns=['ID', 'target'])\n",
    "pred_df['target'] = preds_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "155e1fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample_submission_df = pd.read_csv(\"datasets_fin/sample_submission.csv\")\n",
    "sample_submission_df = pd.read_csv(\"../sample_submission.csv\")\n",
    "assert (sample_submission_df['ID'] == pred_df['ID']).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d79d5b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred-sz-k.csv saved!!\n"
     ]
    }
   ],
   "source": [
    "pred_df.to_csv(\"pred-sz-k.csv\", index=False)\n",
    "\n",
    "print(\"pred-sz-k.csv saved!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cc61cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
